{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "\n",
    "Assunig you are working for a bank. you need to predict how many transactions each customer will make next year\n",
    "\n",
    "This is how Linear Regression works. \n",
    "\n",
    "![](../images/nn_linear_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression assumes that it's the sum of individual parts. Like there is some effect of age, some effect of bank balance and so on. \n",
    "\n",
    "But there is also interaction between these parts which is not taken into acocunt by these. \n",
    "\n",
    "\n",
    "\n",
    "### Interactions\n",
    "Neural networks account for interactions really well \n",
    "\n",
    "Deep learning uses especially powerful neural networks\n",
    "\n",
    "* Text\n",
    "* Images \n",
    "* Videos \n",
    "* Audio \n",
    "* Source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How interactions are modelled?**\n",
    "\n",
    "![](../images/interactions.png)\n",
    "\n",
    "Here we add a function to understand the interaction between these 2 and then we try to predict them. \n",
    "\n",
    "But this is simple. In reality something like this happens \n",
    "\n",
    "![](../images/nn_interations.png)\n",
    "\n",
    "\n",
    "Left Input layer - takes features \n",
    "\n",
    "Right - output layer prediction)\n",
    "\n",
    "In the middle - Hidden layers (not from the world)\n",
    "\n",
    "Each circle is a **node**. Each node models ability to capture interactions. \n",
    "\n",
    "More nodes = more interactions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How NN use data to make predictions\n",
    "\n",
    "Let's again see how many transactions to make \n",
    "\n",
    "**Make predictions based on:** \n",
    "* Number of children\n",
    "* Number of existing accounts\n",
    "\n",
    "These are the features or input\n",
    "\n",
    "![](../images/fp_1.png)\n",
    "\n",
    "\n",
    "Each Line has a weight to signify how strongly that input affects that node. \n",
    "\n",
    "These weights are parameters we need to work upon. \n",
    "\n",
    "to calculate the values of the hidden layer we\n",
    "\n",
    "1. multiply each input by the node weight\n",
    "2. Calculate the sum \n",
    "\n",
    "\n",
    "Repeat the process for each layer. \n",
    "\n",
    "\n",
    "#### Forward propagation\n",
    "1. Multiply - add process\n",
    "2. Dot product\n",
    "3. Forward propagation for one data point at a time 4. 4. Output is the prediction for that data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "input_data = np.array([2,3])\n",
    "\n",
    "weights = {'node_0': np.array([1,1]),\n",
    "           'node_1': np.array([-1,1]),\n",
    "           'output': np.array([2,-1])}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate node 0 value: node_0_value\n",
    "node_0_value = (input_data * weights['node_0']).sum()\n",
    "\n",
    "# Calculate node 1 value: node_1_value\n",
    "node_1_value = (input_data * weights['node_1']).sum()\n",
    "\n",
    "# Put node values into array: hidden_layer_outputs\n",
    "hidden_layer_outputs = np.array([node_0_value, node_1_value])\n",
    "\n",
    "print(hidden_layer_outputs)\n",
    "\n",
    "prediction = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function \n",
    "\n",
    "What we saw now is just another way to represent linear models. So we are not acheiving anything more than simple linear regression in the relationships. \n",
    "\n",
    "We need to model them using non-linear relationships and we can do this by using an activation function on the value of nodes. \n",
    "\n",
    "A famous function was tanh\n",
    "\n",
    "![](../images/TanhReal.gif)\n",
    "\n",
    "How will this be applied\n",
    "\n",
    "![](../images/activation_tanh.png)\n",
    "\n",
    "\n",
    "Recent research has produced a much better and faster Activation function \n",
    "\n",
    "### Rectified Linear Unit (ReLU)\n",
    "\n",
    "![](../images/activation_relu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rectified Linear Activation Function\n",
    "\n",
    "\n",
    "The rectified linear activation function (called ReLU) has been shown to lead to very high-performance networks. This function takes a single number as an input, returning 0 if the input is negative, and the input if the input is positive.\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "relu(3) = 3 \n",
    "\n",
    "relu(-3) = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "def relu(input):\n",
    "    '''Define your relu activation function here'''\n",
    "    # Calculate the value for the output of the relu function: output\n",
    "    output = max(0, input)\n",
    "    \n",
    "    # Return the value just calculated\n",
    "    return(output)\n",
    "\n",
    "# Calculate node 0 value: node_0_output\n",
    "node_0_input = (input_data * weights['node_0']).sum()\n",
    "node_0_output = relu(node_0_input)\n",
    "\n",
    "# Calculate node 1 value: node_1_output\n",
    "node_1_input = (input_data * weights['node_1']).sum()\n",
    "node_1_output = relu(node_1_input)\n",
    "\n",
    "# Put node values into array: hidden_layer_outputs\n",
    "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "\n",
    "# Calculate model output (do not apply relu)\n",
    "model_output = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "# Print model output\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/activaation_deeper.png)\n",
    "\n",
    "\n",
    "\n",
    "![](../images/activation_Deeper_answer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the network to many observations/rows of data\n",
    "\n",
    "You'll now define a function called predict_with_network() which will generate predictions for multiple data observations, which are pre-loaded as input_data. As before, weights are also pre-loaded. In addition, the relu() function you defined in the previous exercise has been pre-loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 12]\n"
     ]
    }
   ],
   "source": [
    "# Define predict_with_network()\n",
    "def predict_with_network(input_data_row, weights):\n",
    "\n",
    "    # Calculate node 0 value\n",
    "    node_0_input = (input_data_row * weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "\n",
    "    # Calculate node 1 value\n",
    "    node_1_input = (input_data_row * weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_layer_outputs\n",
    "    hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "    \n",
    "    # Calculate model output\n",
    "    input_to_final_layer = np.dot(hidden_layer_outputs,weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "    \n",
    "    # Return model output\n",
    "    return(model_output)\n",
    "\n",
    "\n",
    "# Create empty list to store prediction results\n",
    "results = []\n",
    "for input_data_row in input_data:\n",
    "    # Append prediction to results\n",
    "    results.append(predict_with_network(input_data_row,weights))\n",
    "\n",
    "# Print results\n",
    "print(results)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propagation in a deeper network\n",
    "\n",
    "You now have a model with 2 hidden layers. The values for an input data point are shown inside the input nodes. The weights are shown on the edges/lines. What prediction would this model make on this data point?\n",
    "\n",
    "Assume the activation function at each node is the identity function. That is, each node's output will be the same as its input. So the value of the bottom node in the first hidden layer is -1, and not 0, as it would be if the ReLU activation function was used.\n",
    "![]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-layer neural networks\n",
    "\n",
    "In this exercise, you'll write code to do forward propagation for a neural network with 2 hidden layers. Each hidden layer has two nodes. The input data has been preloaded as input_data. The nodes in the first hidden layer are called node_0_0 and node_0_1. Their weights are pre-loaded as weights['node_0_0'] and weights['node_0_1'] respectively.\n",
    "\n",
    "The nodes in the second hidden layer are called node_1_0 and node_1_1. Their weights are pre-loaded as weights['node_1_0'] and weights['node_1_1'] respectively.\n",
    "\n",
    "We then create a model output from the hidden nodes using weights pre-loaded as weights['output']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_with_network(input_data):\n",
    "    # Calculate node 0 in the first hidden layer\n",
    "    node_0_0_input = (input_data * weights['node_0_0']).sum()\n",
    "    node_0_0_output = relu(node_0_0_input)\n",
    "\n",
    "    # Calculate node 1 in the first hidden layer\n",
    "    node_0_1_input = (input_data * weights['node_0_1']).sum()\n",
    "    node_0_1_output = relu(node_0_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_0_outputs\n",
    "    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])\n",
    "    \n",
    "    # Calculate node 0 in the second hidden layer\n",
    "    node_1_0_input = (hidden_0_outputs * weights['node_1_0']).sum()\n",
    "    node_1_0_output = relu(node_1_0_input)\n",
    "\n",
    "    # Calculate node 1 in the second hidden layer\n",
    "    node_1_1_input = (hidden_0_outputs * weights['node_1_1']).sum()\n",
    "    node_1_1_output = relu(node_1_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_1_outputs\n",
    "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
    "\n",
    "    # Calculate model output: model_output\n",
    "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
    "    \n",
    "    # Return model_output\n",
    "    return(model_output)\n",
    "\n",
    "output = predict_with_network(input_data)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
